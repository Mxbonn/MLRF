guid,question,answer,paper_title,paper_url,explanation,tags
BKbQ-a*K5Z,What is according to the <b>RetinaNet </b>paper the <b>main obstacle for one-stage detectors</b> to achieve state-of-the-art accuracy?,<b>Class imbalance</b> during training.,Focal Loss for Dense Object Detection,https://arxiv.org/abs/1708.02002,<b>Note</b>: More recent one-stage detectors have not adopted focal loss and have shown that it does not necessarily result in better accuracy.,
rX(!&sGK|#,How is <b>class imbalance</b> an issue for object detectors and how does <b>SSD </b>solve this issue compared to <b>RetinaNet</b>?,One-stage object detectors evaluate \(10^4-10^5\) candidate locations per image but only a few locations contain objects. This imbalance causes two problems: <br>(1) training is inefficient as most locations are easy negatives <br>(2)&nbsp; the easy negatives can overwhelm training and lead to degenerate models.<br><b>SSD </b>solves this by <b>hard negative mining</b>.<br><b>RetinaNet</b> uses <b>Focal Loss</b> that down-weights easy examples.,Focal Loss for Dense Object Detection,https://arxiv.org/abs/1708.02002,,
QG?M|;Vez0,Give the mathematical definition for the&nbsp;<b>Focal Loss</b>.,"<b>\[FL(p_t) = -(1 - p_t)^{\gamma} log(p_t)\]<br></b>with \(\gamma \ge 0\) a tunable <i>focusing</i>&nbsp;parameter and where&nbsp;<br>\[ p_t = \begin{cases} p &amp; \text{if } y = 1 \\<br>1 - p &amp; \text{if } y = 0 \end{cases} \]<br>with \(p \in [0,1]\) the model's estimated probability for the class with label \(y=1\)",Focal Loss for Dense Object Detection,https://arxiv.org/abs/1708.02002,"In practice we use an \(\alpha\)-balanced variant of the focal loss:<br><b>\[FL(p_t) = -\alpha_t(1 - p_t)^{\gamma} log(p_t)\]<br></b><img src=""paste-556541a621df1e615336ac514face4107ed4166b.jpg""><b><br></b>",
mUSQ!?#qIV,How does <b>focal loss</b> relate to the <b>cross entropy loss</b>?,"Focal loss adds a modulating factor \((1 - p_t)\) to the cross entropy loss.<br>As \(p_t \to 1\), the factor goes to 0 and the loss for well-classified examples is down-weighted. <br>The focusing parameter&nbsp; \(\gamma\) smoothly adjusts the rate at which easy examples are downweighted. <b>When \(\gamma = 0\), focal loss is equivalent to cross entropy loss</b>, and as \(\gamma\) is increased the effect of the modulating factor is likewise increased.",Focal Loss for Dense Object Detection,https://arxiv.org/abs/1708.02002,"<img src=""paste-556541a621df1e615336ac514face4107ed4166b.jpg"">",
s-f6CF|~x=,How is the <b>focal loss</b>&nbsp;of an entire image calculated?,"The total focal loss of an image is computed as the <b>sum</b> of the focal loss over all anchors, <b>normalized</b> by the&nbsp;number of anchors assigned to a ground-truth box.",Focal Loss for Dense Object Detection,https://arxiv.org/abs/1708.02002,,
e$g#+#_Fyo,Draw the architecture of <b>RetinaNet</b>.,"<img src=""paste-cb15da58ea668d1da71d7664f4000f56c141deeb.jpg""><br>RetinaNet is a <b>one-stage object detector</b>&nbsp;with <b>ResNet </b>as backbone, a feature pyramid network (<b>FPN</b>) as neck and head that is <b>shared </b>for all feature layers.",Focal Loss for Dense Object Detection,https://arxiv.org/abs/1708.02002,"RetinaNet follows the <b>one-stage</b>&nbsp;<b>object detection</b>&nbsp;architecture, the main innovation of RetinaNet was the <b>loss function</b>.",
