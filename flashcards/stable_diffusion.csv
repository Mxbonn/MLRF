guid,question,answer,paper_title,paper_url,explanation,tags
%%Q3*A3`H,Give an overview of the <b>Latent Diffusion Model</b> (Stable Diffusion architecture).,"<img src=""latent-diffusion-arch.png""><br>An encoder \(\mathcal{E}\) is used to compress the input image \(\mathbf{x} \in \mathbb{R}^{H \times W \times 3}\) to a smaller 2D <i>latent</i> vector \(\mathbf{z} = \mathcal{E}(\mathbf{x}) \in \mathbb{R}^{h \times w \times c}\), where the downsampling rate \(f=H/h=W/w=2^m, m \in \mathbb{N}\). A decoder \(\mathcal{D}\) reconstructs the images from the latent vector: \(\tilde{\mathbf{x}} = \mathcal{D}(\mathbf{z})\).<br>The diffusion and denoising processes happen on the latent vector \(\mathbf{z}\).<br>The denoising model is a <b>time-conditioned U-Net</b>, augmented with the <b>cross-attention mechanism to handle flexible conditioning</b> information for image generation.<br>To process \(y\) from various modalities, a domain specific encoder \(\tau_\theta\) that projects \(y\) to an intermediate representation \(\tau_\theta(y) \in \mathbb{R}^{M \times d_\tau}\) is used.<br>\[\begin{aligned}
&amp;\text{Attention}(\mathbf{Q}, \mathbf{K}, \mathbf{V}) = \text{softmax}\Big(\frac{\mathbf{Q}\mathbf{K}^\top}{\sqrt{d}}\Big) \cdot \mathbf{V} \\
&amp;\text{where }\mathbf{Q} = \mathbf{W}^{(i)}_Q \cdot \varphi_i(\mathbf{z}_i),\;
\mathbf{K} = \mathbf{W}^{(i)}_K \cdot \tau_\theta(y),\;
\mathbf{V} = \mathbf{W}^{(i)}_V \cdot \tau_\theta(y) \\
&amp;\text{and }
\mathbf{W}^{(i)}_Q \in \mathbb{R}^{d \times d^i_\epsilon},\;
\mathbf{W}^{(i)}_K, \mathbf{W}^{(i)}_V \in \mathbb{R}^{d \times d_\tau},\;
\varphi_i(\mathbf{z}_i) \in \mathbb{R}^{N \times d^i_\epsilon},\;
\tau_\theta(y) \in \mathbb{R}^{M \times d_\tau}
\end{aligned}\]Where \(\varphi(\mathbf{z}_i) \in \mathbb{R}^{N \times d_\epsilon^i}\)&nbsp;denotes a (flattened) intermediate representation of the UNet implementation \(\epsilon_\theta\).",High-Resolution Image Synthesis with Latent Diffusion Models,https://arxiv.org/abs/2112.10752,,
bt!!NNgMh&,How is the <b>latent diffusion model trained</b>?,The compression part (e.g. encoder \(\mathcal{E}\) and decoder \(\mathcal{D}\)) and diffusion part are trained in different phases (first compression then diffusion).,High-Resolution Image Synthesis with Latent Diffusion Models,https://arxiv.org/abs/2112.10752,Usually the compression part is taken from a pretrained network such as <i>CLIP</i>.,
or*%/E%(t),How does the <b>latent diffusion model</b> <b>avoid</b> arbitratily <b>high-variance</b> latent spaces?,"It proposes two variants to deal with this:<br><ol><li><b>KL-reg</b>: a small Kullback-Leibler penalty is imposed towards a standard normal distribution over the learned latent, similar to a <i>VAE</i>.</li><li><b>VQ-reg</b>: a vector quantization layer is used within the decoder, similar to <i>VQVAE</i> but the quantization layer is absorbed by the decoder.</li></ol>",High-Resolution Image Synthesis with Latent Diffusion Models,https://arxiv.org/abs/2112.10752,,
