guid,question,answer,paper_title,paper_url,explanation,tags
n(bSfU~#u2,"Which <b>metric </b>is a better and more robust way to <b>compare model families</b> (e.g. ResNets vs VGG family) than the traditional way of point estimates or a curve estimate of a handful of picked models (see Fig 1 (a) and (b))<br><img src=""paste-6b860bdb1b0691e2f86c94feeeed1367d2cfc801.jpg"">","Comparing <b>empirical distribution functions (EDFs)</b>&nbsp;is a better way.&nbsp;<br>Specifically one can compare the <b>error EDF:<br>\[F(e) = \frac{1}{n} \sum^n_{i=1} \mathbb{1}[e_i &lt; e]\]<br></b><br>\(F(e)\) gives the fraction of models with error less than e.<br><img src=""paste-78908eece335f4117a6e66fe054acea7613bf2f3.jpg"">",On Network Design Spaces for Visual Recognition,https://arxiv.org/abs/1905.13214,,
y^.|iwu>CD,"What is an issue with the<b> error EDF</b>&nbsp;<b>\[F(e) = \frac{1}{n} \sum^n_{i=1} \mathbb{1}[e_i &lt; e]\] </b>when comparing distributions of different network families, and how can it be solved?","<b>It does not control for confounding factors like network complexity. </b>Model families which in general produce models of a larger complexity tend to have a better error.<br><img src=""paste-525ee15f00c2312faf9e0a0e8da41d7ab092b241.jpg""><br><br>This can be solved by working with a <b style=""text-decoration-line: underline;"">normalized</b>&nbsp;<b>error EDF:<br>\[F(e) = \frac{1}{n} \sum^n_{i=1} w_i\mathbb{1}[e_i &lt; e]\]</b><br><br>In practice, we set the weights for a model set such that its complexity distribution is uniform. Specifically, we bin the complexity range into \(k\) bins, and assign each of the \(m_j\) models that fall into a bin \(j\) a weight \(w_j = \frac{1}{km_j}\)&nbsp;.",On Network Design Spaces for Visual Recognition,https://arxiv.org/abs/1905.13214,"<img src=""paste-73cde3128d35db5563abaacb483cf0633d574d21.jpg"">",
