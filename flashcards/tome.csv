guid,question,answer,paper_title,paper_url,explanation,tags
u7!B<IP5w3,How does&nbsp;<b>LTMP</b>&nbsp;combine token merging and token pruning?,<b>LTMP</b>&nbsp;adds <b>learned threshold masking modules</b> which learn a threshold for both pruning and merging. First token pairs that have a&nbsp;<i>similarity score</i>&nbsp;above the merging threshold are merged and then tokens with a&nbsp;<i>importance score</i>&nbsp;below the pruning threshold are pruned.,Learned Thresholds Token Merging and Pruning for Vision Transformers,https://arxiv.org/abs/2307.10780,,
u~Z4fkR#NN,How many learnable parameters does <b>LTMP</b> introduce?,LTMP introduces only&nbsp;<b>2</b>&nbsp;learnable parameters&nbsp;<b>per transformer block</b>.,Learned Thresholds Token Merging and Pruning for Vision Transformers,https://arxiv.org/abs/2307.10780,"The learnable parameters are the thresholds, one for merging and one for pruning.",
Djl^IVsrBC,What loss function is used to train <b>LTMP</b>?,"\[\mathcal{L} = \mathcal{L}_{CE} + \lambda(r_{target} - r_{FLOPs})^2\]<br>with&nbsp;\(r_{\text{FLOPs}} \approx{} \sum_{l=1}^L \frac{1}{L}\left(\frac{2\bar{\mathbf{m}}^{l-1}nd^2 + (\bar{\mathbf{m}}^{l-1}n)^2d + 4\bar{\mathbf{m}}^{l}nd^2}{6nd^2 + n^2d}\right)\)&nbsp;where&nbsp;they denote \(\phi_{\text{module}}(n,d)\) as a function that calculates the FLOPs of a module based on the number of tokens \(n\) and the embedding dimension \(d\).<br>\(\bar{\mathbf{m}}^l = \frac{1}{n}\sum_{i=1}^n \mathbf{m}^l_i\) is the percentage of input tokens that are kept after the $l$-th threshold masking operation and \(\bar{\mathbf{m}}^0 = 1\).<br>",Learned Thresholds Token Merging and Pruning for Vision Transformers,https://arxiv.org/abs/2307.10780,,
M5a1?fp&-s,How do the learned threshold masks during&nbsp;<b>LTMP</b>&nbsp;mimic the effect of dropping tokens?,"The attention function is modified such that it corresponds to attention as if it was only applied to the tokens that are not merged or pruned.<br>\[\operatorname{Attention\_with\_mask}(\mathbf{Q}, \mathbf{K}, \mathbf{V}, \mathbf{m}) = \mathbf{S}\mathbf{V}\]<br>where, <br>\[\mathbf{S}_{ij} = \frac{\exp(\mathbf{A}_{ij})\mathbf{m}_{j}}{\sum_{k=1}^N\exp(\mathbf{A}_{ik})\mathbf{m}_{k}}, 1\le i,j,k\le n\]<br>and, <br>\[\mathbf{A} = \mathbf{Q}\mathbf{K}^T/\sqrt{d_k} \in \mathbb{R}^{n\times n}\]",Learned Thresholds Token Merging and Pruning for Vision Transformers,https://arxiv.org/abs/2307.10780,,
FMEQvQ11eE,What does <b>LTMP</b> use as the importance score for pruning?,"<span style=""color: rgb(28, 25, 23); background-color: rgb(255, 255, 255);"">LTMP uses the <b>mean column attention score</b> \(s_i = \frac{1}{h \cdot n}\sum_{j=1}^h \sum_{k=1}^n S_{jki}\) which represents the attention \(x_i\) receives.</span>",Learned Thresholds Token Merging and Pruning for Vision Transformers,https://arxiv.org/abs/2307.10780,,
nTst9vggFL,What does the <b>threshold masking module in LTMP</b> look like?,"\[    M(\mathbf{s}^l_i, \theta^l) = \begin{cases}
       1, &amp;\text{if }\mathbf{s}^l_i &gt; \theta^l\\
       0, &amp;\text{otherwise}
    \end{cases}\]<br>&nbsp;where \(\theta\) is the learned threshold.<br>To make the threshold differentiable during backpropagation it is estimated using a straight-through estimator in the backward pass.<br>\(    M(\mathbf{s}^l_i, \theta^l) = \sigma(\frac{\mathbf{s}^l_i - \theta^l}{\tau})\)<br>",Learned Thresholds Token Merging and Pruning for Vision Transformers,https://arxiv.org/abs/2307.10780,,
m@6@Ad5vht,Draw an overview of the <b>LTMP</b> framework.,"<img src=""paste-b12d0399be9f473302709bc2ab178c68d6233c88.jpg"">",Learned Thresholds Token Merging and Pruning for Vision Transformers,https://arxiv.org/abs/2307.10780,,
