guid,question,answer,paper_title,paper_url,explanation,tags
D#qu[&`GYT,Draw the structure of a <b>Squeeze-and-Excitation (SE)</b> block.,"<img src=""a-A-Squeeze-and-Excitation-block12-b-LA-Net-block.png""><br>where the pooling operation is a global pooling operator.",Squeeze-and-Excitation Networks,https://arxiv.org/abs/1709.01507,"A Squeeze-and-Excitation blocks <i>recalibrates </i>the features of a convolutional layer.<br>The features \(U\) are first passed through a <b>squeeze </b>operation, which aggregates the feature maps across spatial dimensions \(H \times W\) to produce a channel descriptor. This descriptor embeds the global distribution of channel-wise feature responses, enabling information from the global receptive field of the network to be leveraged by its lower layers. This is followed by an <b>excitation </b>operation, in which sample-specific activations, learned for each channel by a self-gating mechanism based on channel dependence, govern the excitation of each channel. The feature maps \(U\)&nbsp;are then reweighted to generate the output of the SE block&nbsp;which can then be fed directly into subsequent layers.",
BnwEX%<a_!,What is the purpose of the <i>reduction ratio <b>r</b></i>&nbsp;in <u>Squeeze-and-Excitation</u> layers?,The reduction ratio <i>r</i>&nbsp;is an important hyperparameter which allows to<b> vary the capacity and computational cost</b> of the SE blocks&nbsp;in the model.<br><br>The original paper found \(r = 16\) to be a good trade-off while more recent MBConv blocks with an SE module use \(r = 4\),Squeeze-and-Excitation Networks,https://arxiv.org/abs/1709.01507,,
LOmkPKj^GT,What is the function of Squeeze-and-Excitation blocks?,"SE blocks are a mechanism that allows the network to perform <b>feature recalibration</b>, through which it can learn to use <b>global information </b>to selectively emphasise informative features and suppress less&nbsp;useful ones.",Squeeze-and-Excitation Networks,https://arxiv.org/abs/1709.01507,,
